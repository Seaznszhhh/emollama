# ğŸ¤–Emollama å¿ƒç†å¥åº·è¯Šç–—å¤§æ¨¡å‹

<div align="center">
<img src="figure\Emollama.png" width="400"/>
  <div>&nbsp;</div>
  <div align="center">
  </div>
</div>

---

# ç®€ä»‹

æœ¬é¡¹ç›®ä¸ºåŸºäº[Ollama](https://ollama.com/)è¿›è¡Œæœ¬åœ°å¤§æ¨¡å‹éƒ¨ç½²ã€[langchain](https://www.langchain.com/)å¼€å‘ï¼Œä»¥åŠ[streamlit](https://streamlit.io/)åˆ¶ä½œå‰ç«¯çš„å¿ƒç†æŠ‘éƒè¯Šæ–­æ²»ç–—å¤§æ¨¡å‹ã€‚åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦åŠŸèƒ½ã€‚

1. åŸºäºå¤§æ¨¡å‹æ²Ÿé€šçš„æ™ºèƒ½å¿ƒç†å¥åº·è¯Šæ–­ã€‚
2. åŸºäº RAG çš„å¿ƒç†å¥åº·å¯¹è¯æ²»ç–—ã€‚
3. æ‚£è€…æ¡£æ¡ˆçš„å­˜å–ã€‚

<div align="center">
<img src="figure\intro.png" width="700"/>
  <div>&nbsp;</div>
  <div align="center">
  </div>
</div>

---

# quick start

æœ¬é¡¹ç›®ä½¿ç”¨[Ollama](https://ollama.com/)éƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹ï¼Œå¯å®ç°å¤šç§æœ€æ–°å¤§æ¨¡å‹ä½ç²¾åº¦çš„ä¸€é”®éƒ¨ç½²ï¼Œå¦ˆå¦ˆå†ä¹Ÿä¸ç”¨æ‹…å¿ƒæ˜¾å­˜ä¸å¤Ÿç”¨äº†ã€‚[Ollama](https://ollama.com/)ç›®å‰æ”¯æŒå¤šç§æ“ä½œç³»ç»Ÿï¼Œç”±äºç¬”è€…æ˜¯åœ¨ Linux æœåŠ¡å™¨ä¸Šéƒ¨ç½²ï¼Œæ‰€ä»¥ä¸€ä¸‹ç®€å•å±•ç¤ºåœ¨ Linux ç¯å¢ƒæ€ä¹ˆä½¿ç”¨ Emollamaã€‚

<div align="center">
<img src="figure\ollama.png" width="400"/>
  <div>&nbsp;</div>
  <div align="center">
  </div>
</div>

## clone æœ¬é¡¹ç›®

```shell
git clone https://github.com/Seaznszhhh/emollama.git
```

æ‰“å¼€ä½ çš„å·¥ä½œç›®å½•åè¿è¡Œå…‹éš†ã€‚

## å®‰è£… Ollama

```shell
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
ollama run llama
```

å¦‚æœæˆåŠŸè¿è¡Œå¤§æ¨¡å‹ï¼Œä½ å·²ç»æˆåŠŸéƒ¨ç½²äº† Ollamaã€‚æœ¬é¡¹ç›®ä½¿ç”¨çš„ qwen:14b-chat å’Œ llavaï¼Œéœ€è¦ pull ä¸€ä¸‹æ¨¡å‹ã€‚

```shell
ollama pull qwen:14b-chat
ollama pull llava
```

## å®‰è£…ç¯å¢ƒ

```shell
cd emollama
pip install -r requirements.txt
```

## è¿è¡Œ

```shell
streamlit run ä¸»é¡µé¢.py
```

ç”±äºæ˜¯åœ¨æœåŠ¡å™¨çš„ç«¯å£å¹¶ä¸æ˜¯åœ¨æœ¬æœºï¼Œæ‰€ä»¥æ­¤æ—¶å‡ºç°çš„åœ°å€æ˜¯æ‰“ä¸å¼€çš„ï¼Œè¿˜éœ€è¦è¿›è¡Œä¸€ä¸‹çš„æ­¥éª¤ã€‚

## åœ¨æœ¬åœ°è¿è¡Œ streamlit

ä»¥ autodl ä¸ºä¾‹ï¼Œåœ¨æœ¬åœ°çš„ cmd ä¸­è¿è¡Œä¸‹é¢çš„ä»£ç 

```shell
ssh -CNg -L 8501:127.0.0.1:8501 root@connect.bjb1.seetacloud.com -p 14973
```

8501 è¦æ¢æˆ streamlit run åå‡ºç°çš„åœ°å€æ‰€ç»™çš„ï¼Œ14973 æ¢æˆä½ çš„æœåŠ¡å™¨å®ä¾‹ç»™çš„ç«¯å£ã€‚è¿è¡Œåå‡ºç°è¾“å…¥å¯†ç ï¼Œç²˜è´´æœåŠ¡å™¨å®ä¾‹å¯†ç ï¼Œæ³¨æ„è¿™é‡Œä¸ä¼šæ˜¾ç¤ºå¯†ç ï¼Œç›´æ¥æŒ‰å›è½¦ã€‚ç„¶åæ‰“å¼€æœ¬åœ°æµè§ˆå™¨è¾“å…¥ 127.0.0.1:8501 å°±å¯ä»¥æ‰“å¼€åœ¨è¿œç¨‹æœåŠ¡å™¨è·‘çš„ streamlit é¡µé¢äº†ã€‚

## ä½¿ç”¨ Llama-factory å¯¹æ¨¡å‹è¿›è¡Œ fine-tune

åŸä½œè€…ï¼š@article{zheng2024llamafactory,
title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Yongqiang Ma},
journal={arXiv preprint arXiv:2403.13372},
year={2024},
url={http://arxiv.org/abs/2403.13372}
}

# å®‰è£…éœ€è¦çš„åŒ…

```shell
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
```

# è¿è¡Œ

```shell
CUDA_VISIBLE_DEVICES=0 python src/train_web.py
```

# emollama ä½¿ç”¨å®ä¾‹

å¾…ç»­ã€‚ã€‚ã€‚ã€‚
